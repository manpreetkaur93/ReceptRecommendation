{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affa8a93-bba1-448e-977a-eaf87a9c7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import joblib\n",
    "import os\n",
    "from RAG_Pipeline import TextPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed773164-b6d9-441f-85b7-9dd4851d72db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Kontrollera att filen finns\n",
    "# assert os.path.exists(\"recipes_with_ingredients_and_tags.csv\"), \"Ladda upp CSV-filen till notebook-milj√∂n!\"\n",
    "\n",
    "# # Ladda data\n",
    "# df = pd.read_csv(\"recipes_with_ingredients_and_tags.csv\")\n",
    "# print(\"Data laddad:\")\n",
    "# print(df[['name', 'ingredients']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8fd070-8ebe-4b24-a549-5d2e4783db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definiera synonymer\n",
    "# ingredient_synonyms = {\n",
    "#     'chicken': ['poultry', 'hen', 'chicken breast'],\n",
    "#     'beef': ['ground beef', 'sirloin', 'roast beef'],\n",
    "#     'potato': ['potatoes', 'spuds', 'yukon gold']\n",
    "# }\n",
    "\n",
    "# # Initiera lemmatizer\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def preprocess(text):\n",
    "#     text = str(text).lower()\n",
    "    \n",
    "#     # Ers√§tt synonymer\n",
    "#     for key, synonyms in ingredient_synonyms.items():\n",
    "#         for synonym in synonyms:\n",
    "#             text = re.sub(r'\\b' + re.escape(synonym) + r'\\b', key, text)\n",
    "    \n",
    "#     # Ta bort specialtecken och siffror\n",
    "#     text = re.sub(r'[^\\w\\s,-]', '', text)\n",
    "#     text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "#     # Lemmatisera\n",
    "#     tokens = nltk.word_tokenize(text)\n",
    "#     tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "#     return ' '.join(tokens)\n",
    "\n",
    "# # Applicera preprocessing p√• data\n",
    "# df['processed'] = (\n",
    "#     df['ingredients'].apply(preprocess) + ' ' + \n",
    "#     df['tag_name'].apply(preprocess)\n",
    "# )\n",
    "\n",
    "# # Skriv ut resultat\n",
    "# print(\"\\nProcesserad data:\")\n",
    "# print(df['processed'].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0443c9-4268-4a74-895a-48cb95f52a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skapa TF-IDF pipeline\n",
    "# # Uppdatera TF-IDF med:\n",
    "# tfidf = TfidfVectorizer(\n",
    "#     stop_words='english',\n",
    "#     ngram_range=(1, 2),  # F√•nga flerordsuttryck\n",
    "#     max_features=30000,  # Fler features\n",
    "#     token_pattern=r'\\b[a-z-]+\\b'  # F√•nga bindestreck\n",
    "# )\n",
    "\n",
    "\n",
    "# # Skapa KNN-modell\n",
    "# knn = NearestNeighbors(\n",
    "#     n_neighbors=30,\n",
    "#     metric='cosine',\n",
    "#     algorithm='brute'\n",
    "# )\n",
    "\n",
    "# # Bygg pipeline\n",
    "# model = make_pipeline(tfidf, knn)\n",
    "# model.fit(df['processed'])\n",
    "\n",
    "# # Spara modellen\n",
    "# os.makedirs(\"models\", exist_ok=True)\n",
    "# joblib.dump(model, \"models/knn_pipeline.pkl\")\n",
    "# print(\"\\n‚úÖ Modell sparad!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1804c5e2-ad00-4024-b394-2d33b6f45111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_recommendations(query, top_n=5, min_similarity=0.2):\n",
    "#     # F√∂rbearbeta query\n",
    "#     processed_query = preprocess(query)\n",
    "    \n",
    "#     # H√§mta rekommendationer\n",
    "#     distances, indices = model.named_steps['nearestneighbors'].kneighbors(\n",
    "#         model.named_steps['tfidfvectorizer'].transform([processed_query]),\n",
    "#         n_neighbors=top_n\n",
    "#     )\n",
    "    \n",
    "#     # Formatera resultat\n",
    "#     results = df.iloc[indices[0]]\n",
    "#     results['similarity'] = 1 - distances[0]\n",
    "#     return results[['name', 'ingredients', 'similarity']]\n",
    "\n",
    "# # Testa\n",
    "# test_query = \"chicken, rice, soy sauce\"\n",
    "# print(\"\\nTestresultat:\")\n",
    "# print(get_recommendations(test_query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5af1c1c-0ba0-48db-9d29-dfffc7dbda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sparar allt i en enda cell f√∂r enkel √•teranv√§ndning\n",
    "# final_pipeline = {\n",
    "#     'preprocessor': preprocess,\n",
    "#     'model': model,\n",
    "#     'df': df\n",
    "# }\n",
    "\n",
    "# joblib.dump(final_pipeline, \"models/full_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e790be-b2ac-4366-9516-cbc1baeed233",
   "metadata": {},
   "source": [
    "### Anv√§ndning i Framtiden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc672d72-3730-4c46-aeef-cd843ff198df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recommend(query, top_n=5):\n",
    "#     # Ladda pipeline och data\n",
    "#     loaded_pipeline = joblib.load(\"models/full_pipeline.pkl\")\n",
    "#     df = pd.read_csv(\"recipes_with_ingredients_and_tags.csv\")\n",
    "    \n",
    "#     # F√∂rbearbeta query\n",
    "#     processed_query = loaded_pipeline['preprocessor'](query)\n",
    "    \n",
    "#     # H√§mta n√§rmaste grannar\n",
    "#     tfidf = loaded_pipeline['tfidf']\n",
    "#     knn = loaded_pipeline['knn']\n",
    "#     query_vec = tfidf.transform([processed_query])\n",
    "#     distances, indices = knn.kneighbors(query_vec, n_neighbors=top_n)\n",
    "    \n",
    "#     # Returnera resultat\n",
    "#     return df.iloc[indices[0]][['name', 'ingredients']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce8f8fe4-f184-4661-a9cb-3fc9240ec57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uppdatera sparandet\n",
    "# final_pipeline = {\n",
    "#     'preprocessor': preprocess,\n",
    "#     'tfidf': tfidf,\n",
    "#     'knn': knn\n",
    "# }\n",
    "\n",
    "# joblib.dump(final_pipeline, \"models/full_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee06109a-6594-42c9-95e6-3f1f524c6a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ladda pipeline\n",
    "# loaded_pipeline = joblib.load(\"models/full_pipeline.pkl\")\n",
    "\n",
    "# # Testa med ny funktion\n",
    "# print(recommend(\"beef and potatoes\", top_n=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be96d620-730b-493f-834d-0c5331ef746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importera bibliotek\n",
    "# import pandas as pd\n",
    "# import joblib\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# # Ladda data och modeller\n",
    "# df = pd.read_csv(\"recipes_with_ingredients_and_tags.csv\")\n",
    "# loaded_pipeline = joblib.load(\"models/full_pipeline.pkl\")\n",
    "\n",
    "# def get_recommendations(query, top_n=5):\n",
    "#     # F√∂rbearbeta\n",
    "#     processed_query = loaded_pipeline['preprocessor'](query)\n",
    "    \n",
    "#     # Transformera och h√§mta grannar\n",
    "#     query_vec = loaded_pipeline['tfidf'].transform([processed_query])\n",
    "#     distances, indices = loaded_pipeline['knn'].kneighbors(query_vec, n_neighbors=top_n)\n",
    "    \n",
    "#     # Presentera resultat\n",
    "#     return df.iloc[indices[0]][['name', 'ingredients', 'tag_name']]\n",
    "\n",
    "# # Testa\n",
    "# print(get_recommendations(\"chicken, garlic, soy sauce\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99ce7fa6-1884-42ee-852d-b27fa23cbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TextPreprocessor:\n",
    "#     def __init__(self):\n",
    "#         self.lemmatizer = WordNetLemmatizer()\n",
    "#         self.ingredient_synonyms = {\n",
    "#             'chicken': ['poultry', 'hen', 'chicken breast'],\n",
    "#             'beef': ['ground beef', 'sirloin', 'roast beef'],\n",
    "#             'potato': ['potatoes', 'spuds', 'yukon gold']\n",
    "#         }\n",
    "\n",
    "#     def transform(self, text):\n",
    "#         \"\"\"Hantera b√•de enskilda str√§ngar och hela kolumner\"\"\"\n",
    "#         if isinstance(text, (list, pd.Series)):\n",
    "#             return [self._preprocess(t) for t in text]\n",
    "#         return self._preprocess(text)\n",
    "\n",
    "#     def _preprocess(self, text):\n",
    "#         text = str(text).lower()\n",
    "#         # Ers√§tt synonymer\n",
    "#         for key, synonyms in self.ingredient_synonyms.items():\n",
    "#             for synonym in synonyms:\n",
    "#                 text = re.sub(rf'\\b{re.escape(synonym)}\\b', key, text)\n",
    "#         # Rensa specialtecken\n",
    "#         text = re.sub(r'[^\\w\\s,-]', '', text)\n",
    "#         # Tokenisera och lemmatisera\n",
    "#         tokens = nltk.word_tokenize(text)\n",
    "#         tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "#         return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf7a37c4-870e-4f4f-9a75-27cb9bb6417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Laddar data...\n",
      "Data dimensioner: (4956, 30)\n",
      "                                         name  \\\n",
      "0  1-Day Noodles (Taiwanese Beef Noodle Soup)   \n",
      "1                         1-Hour Banana Bread   \n",
      "2               1-Hour Buffalo  Chicken Wings   \n",
      "\n",
      "                                         ingredients  \n",
      "0  bone-in chuck beef short ribs, beef shin bones...  \n",
      "1  unsalted butter, caster sugar, self-raising fl...  \n",
      "2  nonstick cooking spray, chicken wings, kosher ...  \n"
     ]
    }
   ],
   "source": [
    "# ---- DATAINL√ÑSNING ----\n",
    "print(\"‚úÖ Laddar data...\")\n",
    "df = pd.read_csv(\"recipes_with_ingredients_and_tags.csv\")\n",
    "print(f\"Data dimensioner: {df.shape}\")\n",
    "print(df[['name', 'ingredients']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3d8bf39-dc4a-4e99-93b7-9f2c20fa92fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è Preprocessar data...\n",
      "\n",
      "Exempel p√• processerad data:\n",
      "  processed\n",
      "0       b d\n",
      "1       u o\n",
      "2       n u\n"
     ]
    }
   ],
   "source": [
    "# ---- PREPROCESSING ----\n",
    "print(\"\\n‚öôÔ∏è Preprocessar data...\")\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# Processera varje kolumn som str√§ngar\n",
    "df['processed_ingredients'] = df['ingredients'].apply(lambda x: preprocessor.transform(x)[0])\n",
    "df['processed_tags'] = df['tag_name'].apply(lambda x: preprocessor.transform(x)[0])\n",
    "df['processed'] = df['processed_ingredients'] + ' ' + df['processed_tags']\n",
    "\n",
    "print(\"\\nExempel p√• processerad data:\")\n",
    "print(df[['processed']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f0da7e-9cac-4597-84ce-4e032c00c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- MODELLTR√ÑNING ----\n",
    "# Definiera TF-IDF och KNN komponenterna F√ñRE pipelinen\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=30000,\n",
    "    token_pattern=r'\\b[a-z-]+\\b',\n",
    "    min_df=2 \n",
    ")\n",
    "\n",
    "knn = NearestNeighbors(\n",
    "    n_neighbors=30,\n",
    "    metric='cosine',\n",
    "    algorithm='brute'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c339c88-00f1-4ad0-9d24-43ad67a3d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tr√§nar huvudpipeline...\n",
      "üîç Tr√§nar KNN-pipeline...\n",
      "\n",
      "üíæ Sparar modeller...\n"
     ]
    }
   ],
   "source": [
    "# Skapa pipelines med make_pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "main_pipeline = make_pipeline(tfidf, knn)\n",
    "knn_pipeline = make_pipeline(tfidf, knn)\n",
    "\n",
    "# Tr√§na pipelines\n",
    "print(\"üîç Tr√§nar huvudpipeline...\")\n",
    "main_pipeline.fit(df['processed'])\n",
    "\n",
    "print(\"üîç Tr√§nar KNN-pipeline...\")\n",
    "knn_pipeline.fit(df['processed'])\n",
    "\n",
    "# ---- SPARA MODELLER ----\n",
    "print(\"\\nüíæ Sparar modeller...\")\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9543d244-5024-4b1a-8478-43a265658c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/knn_pipeline.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spara med korrekta stegnamn\n",
    "joblib.dump({\n",
    "    'preprocessor': preprocessor,\n",
    "    'tfidf': main_pipeline.named_steps['tfidfvectorizer'],  # Automatic name from make_pipeline\n",
    "    'knn': main_pipeline.named_steps['nearestneighbors'],   # Automatic name from make_pipeline\n",
    "    'df': df\n",
    "}, \"models/full_pipeline.pkl\")\n",
    "\n",
    "joblib.dump(knn_pipeline, \"models/knn_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "498c90f2-de60-4eb2-8059-36761178f42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Testar huvudpipeline:\n",
      "                             name  \\\n",
      "4943         Zucchini Hash Browns   \n",
      "4942               Zucchini Fries   \n",
      "4941  Zucchini Enchilada Roll-Ups   \n",
      "4940               Zucchini Curry   \n",
      "4939               Zucchini Chips   \n",
      "\n",
      "                                            ingredients  similarity  \n",
      "4943  zucchinis, salt, parmesan cheese, fresh chives...         0.0  \n",
      "4942  zucchinis, panko breadcrumbs, grated parmesan ...         0.0  \n",
      "4941  shredded chicken, salt, onion, red bell pepper...         0.0  \n",
      "4940  oil, red onion, garlic, ginger, coriander, smo...         0.0  \n",
      "4939  large zucchini, olive oil, salt, pepper, garli...         0.0  \n",
      "\n",
      "üß™ Testar KNN-pipeline:\n",
      "                             name  \\\n",
      "4943         Zucchini Hash Browns   \n",
      "4942               Zucchini Fries   \n",
      "4941  Zucchini Enchilada Roll-Ups   \n",
      "4940               Zucchini Curry   \n",
      "4939               Zucchini Chips   \n",
      "\n",
      "                                            ingredients  similarity  \n",
      "4943  zucchinis, salt, parmesan cheese, fresh chives...         0.0  \n",
      "4942  zucchinis, panko breadcrumbs, grated parmesan ...         0.0  \n",
      "4941  shredded chicken, salt, onion, red bell pepper...         0.0  \n",
      "4940  oil, red onion, garlic, ginger, coriander, smo...         0.0  \n",
      "4939  large zucchini, olive oil, salt, pepper, garli...         0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6008\\795500355.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['similarity'] = 1 - distances[0]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6008\\795500355.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['similarity'] = 1 - distances[0]\n"
     ]
    }
   ],
   "source": [
    "# ---- TESTFUNKTIONER ----\n",
    "def get_recommendations(query, pipeline, top_n=5):\n",
    "    \"\"\"H√§mta rekommendationer fr√•n valfri pipeline\"\"\"\n",
    "    processed_query = preprocessor.transform([query])[0]  # H√§mta str√§ngen\n",
    "    \n",
    "    # Anv√§nd korrekta stegnamn fr√•n make_pipeline\n",
    "    query_vec = pipeline.named_steps['tfidfvectorizer'].transform([processed_query])\n",
    "    distances, indices = pipeline.named_steps['nearestneighbors'].kneighbors(query_vec, n_neighbors=top_n)\n",
    "    \n",
    "    results = df.iloc[indices[0]]\n",
    "    results['similarity'] = 1 - distances[0]\n",
    "    return results[['name', 'ingredients', 'similarity']]\n",
    "\n",
    "\n",
    "# Testa b√•da pipelines\n",
    "print(\"\\nüß™ Testar huvudpipeline:\")\n",
    "test_query = \"chicken, rice, soy sauce\"\n",
    "print(get_recommendations(test_query, main_pipeline))\n",
    "\n",
    "print(\"\\nüß™ Testar KNN-pipeline:\")\n",
    "print(get_recommendations(test_query, knn_pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c443d520-de3c-47d9-9d5f-f569386a4872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c a\n"
     ]
    }
   ],
   "source": [
    "# Testa med exempeldata\n",
    "# Testa med exempeldata\n",
    "sample_data = pd.DataFrame({\n",
    "    'ingredients': ['chicken breast, rice, soy sauce'],\n",
    "    'tag_name': ['asian, quick']\n",
    "})\n",
    "\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# Anv√§nd [0] f√∂r att h√§mta den processerade str√§ngen fr√•n listan\n",
    "sample_data['processed'] = (\n",
    "    sample_data['ingredients'].apply(lambda x: preprocessor.transform(x)[0]) + ' ' + \n",
    "    sample_data['tag_name'].apply(lambda x: preprocessor.transform(x)[0])\n",
    ")\n",
    "\n",
    "print(sample_data['processed'].iloc[0])\n",
    "# Output: 'chicken rice soy sauce asian quick'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d20bfd68-797d-434b-b1eb-2beb36601c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stegnamn i huvudpipelinen: dict_keys(['tfidfvectorizer', 'nearestneighbors'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Stegnamn i huvudpipelinen:\", main_pipeline.named_steps.keys())\n",
    "# Output: ['tfidfvectorizer', 'nearestneighbors']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52d6d189-0c31-4cb4-a2e9-25144ee90355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "loaded = joblib.load(\"models/full_pipeline.pkl\")\n",
    "print(hasattr(loaded['preprocessor'], 'transform'))  # Ska vara True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544d2f9-1b0e-40b4-bdd9-b721b5bcb45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
