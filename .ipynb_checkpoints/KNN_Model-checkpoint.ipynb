{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affa8a93-bba1-448e-977a-eaf87a9c7bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed773164-b6d9-441f-85b7-9dd4851d72db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data laddad:\n",
      "                                         name  \\\n",
      "0  1-Day Noodles (Taiwanese Beef Noodle Soup)   \n",
      "1                         1-Hour Banana Bread   \n",
      "2               1-Hour Buffalo  Chicken Wings   \n",
      "\n",
      "                                         ingredients  \n",
      "0  bone-in chuck beef short ribs, beef shin bones...  \n",
      "1  unsalted butter, caster sugar, self-raising fl...  \n",
      "2  nonstick cooking spray, chicken wings, kosher ...  \n"
     ]
    }
   ],
   "source": [
    "# Kontrollera att filen finns\n",
    "assert os.path.exists(\"recipes_with_ingredients_and_tags.csv\"), \"Ladda upp CSV-filen till notebook-miljön!\"\n",
    "\n",
    "# Ladda data\n",
    "df = pd.read_csv(\"recipes_with_ingredients_and_tags.csv\")\n",
    "print(\"Data laddad:\")\n",
    "print(df[['name', 'ingredients']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c8fd070-8ebe-4b24-a549-5d2e4783db78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processerad data:\n",
      "0    bone-in chuck beef short rib , beef shin bone ...\n",
      "1    unsalted butter , caster sugar , self-raising ...\n",
      "2    nonstick cooking spray , chicken wing , kosher...\n",
      "Name: processed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Definiera synonymer\n",
    "ingredient_synonyms = {\n",
    "    'chicken': ['poultry', 'hen', 'chicken breast'],\n",
    "    'beef': ['ground beef', 'sirloin', 'roast beef'],\n",
    "    'potato': ['potatoes', 'spuds', 'yukon gold']\n",
    "}\n",
    "\n",
    "# Initiera lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Ersätt synonymer\n",
    "    for key, synonyms in ingredient_synonyms.items():\n",
    "        for synonym in synonyms:\n",
    "            text = re.sub(r'\\b' + re.escape(synonym) + r'\\b', key, text)\n",
    "    \n",
    "    # Ta bort specialtecken och siffror\n",
    "    text = re.sub(r'[^\\w\\s,-]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Lemmatisera\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Applicera preprocessing på data\n",
    "df['processed'] = (\n",
    "    df['ingredients'].apply(preprocess) + ' ' + \n",
    "    df['tag_name'].apply(preprocess)\n",
    ")\n",
    "\n",
    "# Skriv ut resultat\n",
    "print(\"\\nProcesserad data:\")\n",
    "print(df['processed'].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb0443c9-4268-4a74-895a-48cb95f52a1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'processed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive - Academedia\\Documents\\Receptrekommendation\\ReceptRecommendation\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'processed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Bygg pipeline\u001b[39;00m\n\u001b[32m     19\u001b[39m model = make_pipeline(tfidf, knn)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m model.fit(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprocessed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Spara modellen\u001b[39;00m\n\u001b[32m     23\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive - Academedia\\Documents\\Receptrekommendation\\ReceptRecommendation\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive - Academedia\\Documents\\Receptrekommendation\\ReceptRecommendation\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'processed'"
     ]
    }
   ],
   "source": [
    "# Skapa TF-IDF pipeline\n",
    "# Uppdatera TF-IDF med:\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),  # Fånga flerordsuttryck\n",
    "    max_features=30000,  # Fler features\n",
    "    token_pattern=r'\\b[a-z-]+\\b'  # Fånga bindestreck\n",
    ")\n",
    "\n",
    "\n",
    "# Skapa KNN-modell\n",
    "knn = NearestNeighbors(\n",
    "    n_neighbors=20,\n",
    "    metric='cosine',\n",
    "    algorithm='brute'\n",
    ")\n",
    "\n",
    "# Bygg pipeline\n",
    "model = make_pipeline(tfidf, knn)\n",
    "model.fit(df['processed'])\n",
    "\n",
    "# Spara modellen\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(model, \"models/knn_pipeline.pkl\")\n",
    "print(\"\\n✅ Modell sparad!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1804c5e2-ad00-4024-b394-2d33b6f45111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testresultat:\n",
      "                                             name  \\\n",
      "2770                        Loco Moco Rice Burger   \n",
      "1998  Fried Rice: Soy, Spice, and Everything Nice   \n",
      "3240           One-Pot Chicken Teriyaki With Rice   \n",
      "1997             Fried Rice: Soy, Soy Revolution!   \n",
      "2264                   Ham & Pineapple Fried Rice   \n",
      "\n",
      "                                            ingredients  similarity  \n",
      "2770  rice, soy sauce, ground beef, onion, garlic, p...    0.251971  \n",
      "1998  firm tofu, teriyaki sauce, vegetable oil, kimc...    0.247814  \n",
      "3240  olive oil, chicken breasts, salt, pepper, garl...    0.246656  \n",
      "1997  firm tofu, teriyaki sauce, vegetable oil, kimc...    0.243956  \n",
      "2264  oil, onion, garlic, carrot, bell pepper, ham, ...    0.233739  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3580\\4215314512.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['similarity'] = 1 - distances[0]\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(query, top_n=5, min_similarity=0.2):\n",
    "    # Förbearbeta query\n",
    "    processed_query = preprocess(query)\n",
    "    \n",
    "    # Hämta rekommendationer\n",
    "    distances, indices = model.named_steps['nearestneighbors'].kneighbors(\n",
    "        model.named_steps['tfidfvectorizer'].transform([processed_query]),\n",
    "        n_neighbors=top_n\n",
    "    )\n",
    "    \n",
    "    # Formatera resultat\n",
    "    results = df.iloc[indices[0]]\n",
    "    results['similarity'] = 1 - distances[0]\n",
    "    return results[['name', 'ingredients', 'similarity']]\n",
    "\n",
    "# Testa\n",
    "test_query = \"chicken, rice, soy sauce\"\n",
    "print(\"\\nTestresultat:\")\n",
    "print(get_recommendations(test_query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7f2cf-4957-4771-b120-7b1225b84f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5af1c1c-0ba0-48db-9d29-dfffc7dbda99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/full_pipeline.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparar allt i en enda cell för enkel återanvändning\n",
    "final_pipeline = {\n",
    "    'preprocessor': preprocess,\n",
    "    'model': model,\n",
    "    'df': df\n",
    "}\n",
    "\n",
    "joblib.dump(final_pipeline, \"models/full_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e790be-b2ac-4366-9516-cbc1baeed233",
   "metadata": {},
   "source": [
    "### Användning i Framtiden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc672d72-3730-4c46-aeef-cd843ff198df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(query, top_n=5):\n",
    "    # Ladda pipeline och data\n",
    "    loaded_pipeline = joblib.load(\"models/full_pipeline.pkl\")\n",
    "    df = pd.read_csv(\"recipes_with_ingredients_and_tags.csv\")\n",
    "    \n",
    "    # Förbearbeta query\n",
    "    processed_query = loaded_pipeline['preprocessor'](query)\n",
    "    \n",
    "    # Hämta närmaste grannar\n",
    "    tfidf = loaded_pipeline['tfidf']\n",
    "    knn = loaded_pipeline['knn']\n",
    "    query_vec = tfidf.transform([processed_query])\n",
    "    distances, indices = knn.kneighbors(query_vec, n_neighbors=top_n)\n",
    "    \n",
    "    # Returnera resultat\n",
    "    return df.iloc[indices[0]][['name', 'ingredients']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce8f8fe4-f184-4661-a9cb-3fc9240ec57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/full_pipeline.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uppdatera sparandet\n",
    "final_pipeline = {\n",
    "    'preprocessor': preprocess,\n",
    "    'tfidf': tfidf,\n",
    "    'knn': knn\n",
    "}\n",
    "\n",
    "joblib.dump(final_pipeline, \"models/full_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee06109a-6594-42c9-95e6-3f1f524c6a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            name  \\\n",
      "2629  Kenyan Beef And Potato Pilau By Kiano Moju   \n",
      "3532                              Pique Lo Macho   \n",
      "902             Cheesesteak Stew In A Bread Bowl   \n",
      "\n",
      "                                            ingredients  \n",
      "2629  ground cumin, paprika, ground cardamom, black ...  \n",
      "3532  beef sirloin, hotdogs-sliced into diagonal cut...  \n",
      "902   beef sirloin, salt, pepper, onion powder, all-...  \n"
     ]
    }
   ],
   "source": [
    "# Ladda pipeline\n",
    "loaded_pipeline = joblib.load(\"models/full_pipeline.pkl\")\n",
    "\n",
    "# Testa med ny funktion\n",
    "print(recommend(\"beef and potatoes\", top_n=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be96d620-730b-493f-834d-0c5331ef746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             name  \\\n",
      "3459                 Peking Duck-Inspired Burrito   \n",
      "2592                               Japanese Curry   \n",
      "1900                         Fancy Garlic Noodles   \n",
      "4869  Weekday Meal-prep Chicken Teriyaki Stir-fry   \n",
      "3355                     Pan-Roasted Chicken Rice   \n",
      "\n",
      "                                            ingredients  \\\n",
      "3459  duck breasts, oil, salt, garlic, soy sauce, ri...   \n",
      "2592  kobe beef, garlic, soy sauce, ginger, black pe...   \n",
      "1900  linguine, crimini mushrooms, shiitake mushroom...   \n",
      "4869  chicken breasts, salt, pepper, garlic, soy sau...   \n",
      "3355  chicken breast, greek yogurt, lemon juice, veg...   \n",
      "\n",
      "                                               tag_name  \n",
      "3459  Tongs, Oven Mitts, Baking Pan, Mixing Bowl, St...  \n",
      "2592  Dairy-Free, Low-Fat, Low-Sugar, Low-Calorie, C...  \n",
      "1900  Pescatarian, Dairy-Free, High-Fiber, Special O...  \n",
      "4869  McCormick Easy Dinner, Pyrex, Dry Measuring Cu...  \n",
      "3355         High-Protein, Weeknight, Dinner, Stove Top  \n"
     ]
    }
   ],
   "source": [
    "# Importera bibliotek\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Ladda data och modeller\n",
    "df = pd.read_csv(\"recipes_with_ingredients_and_tags.csv\")\n",
    "loaded_pipeline = joblib.load(\"models/full_pipeline.pkl\")\n",
    "\n",
    "def get_recommendations(query, top_n=5):\n",
    "    # Förbearbeta\n",
    "    processed_query = loaded_pipeline['preprocessor'](query)\n",
    "    \n",
    "    # Transformera och hämta grannar\n",
    "    query_vec = loaded_pipeline['tfidf'].transform([processed_query])\n",
    "    distances, indices = loaded_pipeline['knn'].kneighbors(query_vec, n_neighbors=top_n)\n",
    "    \n",
    "    # Presentera resultat\n",
    "    return df.iloc[indices[0]][['name', 'ingredients', 'tag_name']]\n",
    "\n",
    "# Testa\n",
    "print(get_recommendations(\"chicken, garlic, soy sauce\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c24577d-47f1-45f8-8724-efaa9fea6606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Träffar (≥2 ingredienser): 0/10\n"
     ]
    }
   ],
   "source": [
    "#prestanda test\n",
    "def snabb_test(query, expected_ingredients, top_n=5, min_overlap=2):\n",
    "    results = get_recommendations(query, top_n)\n",
    "    träffar = 0\n",
    "    expected = set(preprocess(expected_ingredients).split(', '))\n",
    "    \n",
    "    for _, row in results.iterrows():\n",
    "        ingredients = set(preprocess(row['ingredients']).split())\n",
    "        overlap = len(ingredients & expected)\n",
    "        if overlap >= min_overlap:\n",
    "            träffar += 1\n",
    "    \n",
    "    print(f\"Träffar (≥{min_overlap} ingredienser): {träffar}/{top_n}\")\n",
    "    return results\n",
    "\n",
    "# Testa med lägre krav\n",
    "testa = snabb_test(\n",
    "    \"chicken, rice, soy sauce\",\n",
    "    \"chicken, rice, soy sauce\",\n",
    "    top_n=10,\n",
    "    min_overlap=2  # Acceptera recept med minst 2 av 3 ingredienser\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f817dce4-bfa6-4cee-bc27-3f4329b3a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finns 'Chicken Teriyaki Bowl' i datan? False\n"
     ]
    }
   ],
   "source": [
    "mask = df['name'].str.contains(\"Chicken Teriyaki Bowl\", case=False)\n",
    "print(\"Finns 'Chicken Teriyaki Bowl' i datan?\", mask.any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1080b8-9e3d-473e-a8d5-43b4f606288a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
